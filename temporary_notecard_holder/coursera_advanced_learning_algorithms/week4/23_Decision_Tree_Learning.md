23

## Title
Decision Tree Learning 

## Description
Overall Method:
1. Start with all examples at root
2. calc information gain for all possible features, pick one highest info gain
3. split dataset left/right according to that feature
4. repeat on each branch until stopping criteria met
  - node is 100% one class
  - splitting a node will result in tree exceeding max depth
  - information gain from additional splits is below threshold

## Additional Notes


## Linked Cards
{{ direct link to another card }}

## Tags
[[ Machine Learning ]] 
